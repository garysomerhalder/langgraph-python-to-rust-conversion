# OPS-002: Configure Observability Backends

## 📋 Task Overview
**ID:** OPS-002
**Title:** Deploy and configure observability backends (Prometheus, Grafana, Jaeger)
**Status:** 🔴 RED - MISSING
**Priority:** P1 - CRITICAL (After P0 blockers)
**Category:** Operations
**Estimated Days:** 1 week
**Phase:** Production Infrastructure
**Dependencies:** OPS-001 (CI/CD should deploy these)
**Created:** 2025-10-01

## 🎯 Objective
Deploy complete observability stack to enable production monitoring, debugging, and performance analysis. Code is instrumented but has no backends to send data to.

## 📝 Current State
- ✅ **Instrumentation exists** - OpenTelemetry integrated
- ✅ **Metrics defined** - p50/p95/p99 latency tracked
- ✅ **Tracing integrated** - Spans created in code
- ❌ **No metrics backend** - Prometheus not deployed
- ❌ **No dashboards** - Grafana not configured
- ❌ **No trace backend** - Jaeger not deployed
- ❌ **No log aggregation** - Logs go to stdout only
- ❌ **No alerting** - No alerts configured

## ✅ Acceptance Criteria

### 🔴 RED Phase - Define Observability Requirements
- [ ] **Metrics collection** - All application metrics captured
- [ ] **Distributed tracing** - Full request flow visibility
- [ ] **Log aggregation** - Centralized logging
- [ ] **Dashboards** - Key metrics visualized
- [ ] **Alerting** - Critical issues trigger notifications
- [ ] **SLI/SLO tracking** - Service level objectives monitored

### 🟡 YELLOW Phase - Basic Deployment
- [ ] **Deploy Prometheus** - Metrics collection working
- [ ] **Deploy Grafana** - Basic dashboards created
- [ ] **Deploy Jaeger** - Trace collection working
- [ ] **Configure exporters** - App → backends connected
- [ ] **Basic alerts** - Critical failures alert

### 🟢 GREEN Phase - Production Observability
- [ ] **Complete dashboards** - All key metrics visualized
- [ ] **Advanced alerting** - Predictive and anomaly alerts
- [ ] **Log aggregation** - ELK or Loki deployed
- [ ] **Retention policies** - Data lifecycle management
- [ ] **High availability** - Redundant backends
- [ ] **Security** - TLS, authentication, RBAC
- [ ] **Automation** - Dashboard/alert as code

## 🔧 Technical Implementation

### Docker Compose Stack
```yaml
# docker-compose.observability.yml
version: '3.8'

services:
  prometheus:
    image: prom/prometheus:latest
    ports:
      - "9090:9090"
    volumes:
      - ./prometheus.yml:/etc/prometheus/prometheus.yml
      - prometheus_data:/prometheus
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.retention.time=30d'
      - '--web.enable-lifecycle'
    networks:
      - observability

  grafana:
    image: grafana/grafana:latest
    ports:
      - "3000:3000"
    environment:
      - GF_SECURITY_ADMIN_PASSWORD=${GRAFANA_PASSWORD}
      - GF_INSTALL_PLUGINS=grafana-piechart-panel
    volumes:
      - grafana_data:/var/lib/grafana
      - ./grafana/dashboards:/etc/grafana/provisioning/dashboards
      - ./grafana/datasources:/etc/grafana/provisioning/datasources
    networks:
      - observability

  jaeger:
    image: jaegertracing/all-in-one:latest
    ports:
      - "5775:5775/udp"  # Zipkin/Thrift
      - "6831:6831/udp"  # Compact Thrift
      - "6832:6832/udp"  # Binary Thrift
      - "5778:5778"      # Config
      - "16686:16686"    # UI
      - "14268:14268"    # Collector
      - "14250:14250"    # gRPC
    environment:
      - COLLECTOR_ZIPKIN_HOST_PORT=:9411
      - COLLECTOR_OTLP_ENABLED=true
    networks:
      - observability

  loki:
    image: grafana/loki:latest
    ports:
      - "3100:3100"
    volumes:
      - ./loki-config.yml:/etc/loki/local-config.yaml
      - loki_data:/loki
    command: -config.file=/etc/loki/local-config.yaml
    networks:
      - observability

  promtail:
    image: grafana/promtail:latest
    volumes:
      - ./promtail-config.yml:/etc/promtail/config.yml
      - /var/log:/var/log:ro
      - /var/lib/docker/containers:/var/lib/docker/containers:ro
    command: -config.file=/etc/promtail/config.yml
    networks:
      - observability

volumes:
  prometheus_data:
  grafana_data:
  loki_data:

networks:
  observability:
    driver: bridge
```

### Prometheus Configuration
```yaml
# prometheus.yml
global:
  scrape_interval: 15s
  evaluation_interval: 15s

alerting:
  alertmanagers:
    - static_configs:
        - targets: ['alertmanager:9093']

rule_files:
  - "alerts/*.yml"

scrape_configs:
  - job_name: 'langgraph'
    static_configs:
      - targets: ['langgraph:8080']
    metrics_path: '/metrics'

  - job_name: 'node-exporter'
    static_configs:
      - targets: ['node-exporter:9100']

  - job_name: 'cadvisor'
    static_configs:
      - targets: ['cadvisor:8080']
```

### Grafana Dashboards (as Code)
```json
{
  "dashboard": {
    "title": "LangGraph Rust Metrics",
    "panels": [
      {
        "title": "Request Rate",
        "targets": [
          {
            "expr": "rate(http_requests_total[5m])"
          }
        ]
      },
      {
        "title": "Latency (p50/p95/p99)",
        "targets": [
          {
            "expr": "histogram_quantile(0.50, http_request_duration_seconds)"
          },
          {
            "expr": "histogram_quantile(0.95, http_request_duration_seconds)"
          },
          {
            "expr": "histogram_quantile(0.99, http_request_duration_seconds)"
          }
        ]
      },
      {
        "title": "Error Rate",
        "targets": [
          {
            "expr": "rate(http_requests_total{status=~'5..'}[5m])"
          }
        ]
      },
      {
        "title": "Active Workflows",
        "targets": [
          {
            "expr": "langgraph_active_workflows"
          }
        ]
      }
    ]
  }
}
```

### Alert Rules
```yaml
# alerts/langgraph.yml
groups:
  - name: langgraph
    interval: 30s
    rules:
      - alert: HighErrorRate
        expr: rate(http_requests_total{status=~"5.."}[5m]) > 0.05
        for: 5m
        labels:
          severity: critical
        annotations:
          summary: High error rate detected
          description: "Error rate is {{ $value | humanizePercentage }}"

      - alert: HighLatency
        expr: histogram_quantile(0.95, http_request_duration_seconds) > 1
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: High latency detected
          description: "95th percentile latency is {{ $value }}s"

      - alert: WorkflowFailures
        expr: rate(langgraph_workflow_failures_total[5m]) > 0.1
        for: 5m
        labels:
          severity: critical
        annotations:
          summary: High workflow failure rate
          description: "Workflow failure rate is {{ $value | humanizePercentage }}"
```

### Application Integration
```rust
// src/observability/metrics.rs
use prometheus::{Encoder, TextEncoder, Counter, Histogram, Gauge};

lazy_static! {
    static ref REQUEST_COUNTER: Counter = Counter::new(
        "http_requests_total",
        "Total number of HTTP requests"
    ).unwrap();

    static ref REQUEST_DURATION: Histogram = Histogram::with_opts(
        HistogramOpts::new(
            "http_request_duration_seconds",
            "HTTP request latency"
        ).buckets(vec![0.001, 0.01, 0.1, 0.5, 1.0, 5.0])
    ).unwrap();

    static ref ACTIVE_WORKFLOWS: Gauge = Gauge::new(
        "langgraph_active_workflows",
        "Number of active workflows"
    ).unwrap();
}

// Metrics endpoint
pub async fn metrics_handler() -> Result<String, Error> {
    let encoder = TextEncoder::new();
    let metric_families = prometheus::gather();
    let mut buffer = vec![];
    encoder.encode(&metric_families, &mut buffer)?;
    Ok(String::from_utf8(buffer)?)
}
```

## 📊 Key Metrics to Track

### Application Metrics
- **Request rate** - Requests per second
- **Latency** - p50, p95, p99 percentiles
- **Error rate** - 4xx and 5xx responses
- **Saturation** - Resource utilization

### Business Metrics
- **Workflow completion rate**
- **Checkpoint save/restore times**
- **State synchronization lag**
- **Backup success rate**

### Infrastructure Metrics
- **CPU utilization**
- **Memory usage**
- **Disk I/O**
- **Network throughput**

## 🎯 SLI/SLO Definitions

### Service Level Indicators (SLIs)
- **Availability**: Successful requests / Total requests
- **Latency**: 95th percentile response time
- **Error rate**: Failed requests / Total requests
- **Throughput**: Workflows processed per minute

### Service Level Objectives (SLOs)
- **Availability**: 99.9% (three nines)
- **Latency**: p95 < 500ms
- **Error rate**: < 1%
- **Throughput**: > 1000 workflows/minute

## 🔒 Security Configuration

### Authentication
```yaml
# Prometheus
basic_auth_users:
  admin: $2y$10$... # bcrypt hash

# Grafana
[auth.basic]
enabled = true

[auth.ldap]
enabled = true
config_file = /etc/grafana/ldap.toml

# Jaeger
--query.bearer-token-propagation=true
```

### TLS Configuration
```yaml
tls_config:
  cert_file: /etc/ssl/certs/prometheus.crt
  key_file: /etc/ssl/private/prometheus.key
  client_auth_type: RequireAndVerifyClientCert
  client_ca_file: /etc/ssl/certs/ca.crt
```

## 📈 Kubernetes Deployment

### Helm Installation
```bash
# Add Helm repositories
helm repo add prometheus-community https://prometheus-community.github.io/helm-charts
helm repo add grafana https://grafana.github.io/helm-charts
helm repo add jaegertracing https://jaegertracing.github.io/helm-charts

# Install Prometheus Operator
helm install prometheus prometheus-community/kube-prometheus-stack \
  --namespace monitoring \
  --create-namespace \
  --values prometheus-values.yml

# Install Jaeger
helm install jaeger jaegertracing/jaeger \
  --namespace monitoring \
  --values jaeger-values.yml

# Install Loki Stack
helm install loki grafana/loki-stack \
  --namespace monitoring \
  --values loki-values.yml
```

## 🚀 Production Checklist
- [ ] High availability setup (multiple replicas)
- [ ] Persistent storage configured
- [ ] Backup strategy for metrics data
- [ ] Retention policies configured
- [ ] Alert notification channels (PagerDuty, Slack)
- [ ] Dashboard version control
- [ ] Capacity planning (storage growth)
- [ ] Disaster recovery procedures
- [ ] Runbooks for common alerts

## 📝 Future Enhancements
- APM integration (DataDog, New Relic)
- Machine learning anomaly detection
- Custom metrics SDK
- Mobile app for monitoring
- Cost optimization tracking
- Business KPI dashboards
- Synthetic monitoring
- Real user monitoring (RUM)